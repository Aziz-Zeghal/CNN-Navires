{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-20T14:32:59.654526Z",
     "iopub.status.busy": "2025-05-20T14:32:59.654184Z",
     "iopub.status.idle": "2025-05-20T14:33:00.006476Z",
     "shell.execute_reply": "2025-05-20T14:33:00.005488Z",
     "shell.execute_reply.started": "2025-05-20T14:32:59.654500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Misc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.api.utils import image_dataset_from_directory\n",
    "from keras.api.models import Sequential, Model\n",
    "from keras.api.layers import Dense, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Input, Concatenate, UpSampling2D\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Tuning\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Deactivate XLA compilation\n",
    "tf.config.optimizer.set_jit(False)\n",
    "# TensorFlow, check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "\n",
    "# Either on Kaggle or local\n",
    "RAW_DATA = \"/kaggle/input\" if os.path.exists(\"/kaggle/input\") else f\"{os.getcwd()}/data\"\n",
    "RAW_DATA = os.path.join(RAW_DATA, \"navires-2025\")\n",
    "\n",
    "LABEL_TO_VALUE = {'coastguard':0, 'containership':1, 'corvette':2, 'cruiser':3,\n",
    "           'cv':4, 'destroyer':5, 'ferry':6, 'methanier':7, 'sailing':8,\n",
    "           'smallfish':9, 'submarine':10, 'tug':11, 'vsmallfish':12}\n",
    "\n",
    "VALUE_TO_LABEL = {v: k for k, v in LABEL_TO_VALUE.items()}\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "DATA_PATH = f\"{os.getcwd()}/data/ships32\"\n",
    "\n",
    "\n",
    "print(f\"RAW_DATA: {RAW_DATA}\")\n",
    "print(f\"DATA_PATH: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T14:33:05.609782Z",
     "iopub.status.busy": "2025-05-20T14:33:05.609364Z",
     "iopub.status.idle": "2025-05-20T14:33:08.688126Z",
     "shell.execute_reply": "2025-05-20T14:33:08.686850Z",
     "shell.execute_reply.started": "2025-05-20T14:33:05.609757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If the ships32 folder does not exist in data, unpack the ships.tgz file\n",
    "!if [ ! -d data ]; then mkdir data; fi\n",
    "!if [ ! -d data/ships32 ]; then tar xzf {RAW_DATA}/ships.tgz -C data; fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Extract data\n",
    "\n",
    "Mapping should be:\n",
    "```python\n",
    "{'coastguard':0, 'containership':1, 'corvette':2, 'cruiser':3, 'cv':4, 'destroyer':5, 'ferry':6, 'methanier':7, 'sailing':8, 'smallfish':9, 'submarine':10, 'tug':11, 'vsmallfish':12}\n",
    "```\n",
    "We will use the `image_dataset_from_directory` function from `keras.utils` to get a `tf.data.Dataset` object.\n",
    "\n",
    "Data is already batched, we take multiple images at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split depends on the subset and seed\n",
    "features = {\n",
    "    \"directory\" : DATA_PATH,\n",
    "    \"labels\" : \"inferred\",\n",
    "    \"label_mode\" : \"int\",\n",
    "    \"batch_size\" : BATCH_SIZE,\n",
    "    \"image_size\" : (IMG_SIZE, IMG_SIZE),\n",
    "    \"seed\" : SEED\n",
    "}\n",
    "\n",
    "ds = image_dataset_from_directory(**features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few of the images to check the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_batch(batch):\n",
    "    \"\"\"Display a batch of images and labels.\"\"\"\n",
    "    \n",
    "    \n",
    "    for images, labels in batch:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "\n",
    "            # Remove ticks and grid\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "\n",
    "            # Display the image\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "            # Display the label\n",
    "            plt.title(VALUE_TO_LABEL[labels[i].numpy()])\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_batch(ds.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing\n",
    "\n",
    "We normalize the data to be in the range [0, 1] by dividing by 255.0 (images should now be black)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "\n",
    "zoom or crop to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cardinality().numpy() * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_layer = keras.layers.RandomRotation(factor=0.05, seed=SEED)\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image, seed=SEED)\n",
    "    image = tf.image.random_hue(image, max_delta=0.05, seed=SEED)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.05, seed=SEED)\n",
    "    return image, label\n",
    "\n",
    "# First flip images and hue\n",
    "more_images = ds.map(augment)\n",
    "augmented_ds = ds.concatenate(more_images).shuffle(1000, seed=SEED)\n",
    "\n",
    "# Then, rotate all images\n",
    "more_images = ds.map(lambda x, y: (rotation_layer(x), y))\n",
    "augmented_ds = augmented_ds.concatenate(more_images).shuffle(1000, seed=SEED)\n",
    "\n",
    "display_batch(augmented_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_ds.cardinality().numpy() * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize and rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(images, labels):\n",
    "    \"\"\"Preprocess the images.\"\"\"\n",
    "\n",
    "    # Resize and rescale the images\n",
    "    image = images / 255.0\n",
    "    \n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_ds = augmented_ds.map(preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = augmented_ds.cardinality().numpy()\n",
    "train_count = int(0.8 * total_count)\n",
    "val_count = int(0.2 * total_count)\n",
    "\n",
    "# Shuffle before splitting for randomness\n",
    "augmented_ds = augmented_ds.shuffle(buffer_size=total_count, seed=SEED)\n",
    "\n",
    "train_ds = augmented_ds.take(train_count)\n",
    "val_ds = augmented_ds.skip(train_count).take(val_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.cardinality().numpy() * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "    \n",
    "    for i in range(4):  # 4 blocks\n",
    "        filters = hp.Int(f\"filters_{i}\", min_value=32, max_value=512, step=32)\n",
    "        model.add(Conv2D(filters=filters, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(filters=filters, kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(rate=hp.Float(f\"dropout_{i}\", 0.1, 0.5, step=0.1)))\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(units=hp.Int(\"dense_units\", 32, 512, step=32), activation=\"relu\"))\n",
    "    model.add(Dense(units=len(LABEL_TO_VALUE)))    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")),\n",
    "        loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"keras_tuner_dir\",\n",
    "    project_name=\"ship_model_tuning\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only if you want to tune the model\n",
    "# tuner.search(train_ds, validation_data=val_ds, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tuner.get_best_models(num_models=1)[0]\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model A: Normal CNN\n",
    "After testing some models, the following architecture has the saved hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=320, kernel_size=(3, 3), activation=\"relu\", padding=\"same\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=320, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.1),\n",
    "\n",
    "    Conv2D(filters=288, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=288, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.3),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "], name=\"ship_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Sequential([\n",
    "    Dense(288, activation=\"relu\"),\n",
    "    Dense(len(LABEL_TO_VALUE))\n",
    "], name=\"ship_output\")\n",
    "\n",
    "model.add(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.00025431),\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, min_delta=0.0008, restore_best_weights=True, verbose=1),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=4, cooldown=2, min_delta=0.0008, min_lr=1e-6, verbose=1),\n",
    "             keras.callbacks.ModelCheckpoint(filepath='data/model.keras', monitor='val_loss', save_best_only=True, mode=\"min\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nombre de couches : \", len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B: U-Net\n",
    "The U-Net architecture consists of an encoder-decoder structure with skip connections, which allows the model to capture both high-level and low-level features in the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# encoder_filters = [320, 256, 384]\n",
    "# dropouts = [0.1, 0.3, 0.1]\n",
    "# skips = []\n",
    "# x = inputs\n",
    "\n",
    "# # Encoder (Conv + BN per block)\n",
    "# for filters, drop in zip(encoder_filters, dropouts):\n",
    "#     x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     skips.append(x)\n",
    "#     x = MaxPooling2D((2, 2))(x)\n",
    "#     x = Dropout(drop)(x)\n",
    "\n",
    "# # Bottleneck\n",
    "# x = Conv2D(384, (3, 3), activation='relu', padding='same')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# # Decoder\n",
    "# for filters, skip in zip(reversed(encoder_filters), reversed(skips)):\n",
    "#     x = UpSampling2D((2, 2))(x)\n",
    "#     x = Concatenate()([x, skip])\n",
    "#     x = Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "\n",
    "# # Output head\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(288, activation=\"relu\")(x)\n",
    "# outputs = Dense(len(LABEL_TO_VALUE))(x)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=outputs, name=\"ship_unet_bn\")\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=Adam(learning_rate=0.00025431),\n",
    "#     loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=['accuracy']\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_ds, validation_data=val_ds, epochs=45, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=hist.history[\"val_loss\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Validation Loss\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=hist.history[\"loss\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Train Loss\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Validation loss per epoch\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    legend_title=\"Dataset\",\n",
    "    xaxis=dict(tickmode=\"linear\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"data/best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test accuracy: {test_acc}\")\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(train_ds).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = []\n",
    "for image, label in train_ds.unbatch():\n",
    "    y_labels.append(int(label.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_pred, y_labels, target_names=VALUE_TO_LABEL.values())\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_labels, y_pred, labels=list(LABEL_TO_VALUE.values()))\n",
    "cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "heat = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=VALUE_TO_LABEL.values())\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "heat.plot(ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(f\"{RAW_DATA}/ships_competition.npz\", allow_pickle=True)['X']\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "res = model.predict(X_test).argmax(axis=1)\n",
    "df = pd.DataFrame({\"Category\":res})\n",
    "df.to_csv(\"data/reco_nav.csv\", index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!head data/reco_nav.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'data/reco_nav.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11655307,
     "sourceId": 97843,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "IREN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
